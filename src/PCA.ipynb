{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9781563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "602fe0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64')], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/diabetes_data_encoded.csv').drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "df.columns = [re.sub(r'[^\\w\\s]', '', col) for col in df.columns]\n",
    "df.columns = [re.sub(r'[_]', ' ', col) for col in df.columns]\n",
    "df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d385c1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of Readmitted:\n",
      "Value 0: 90406\n",
      "Value 1: 11357\n",
      "%: 0.12562219321726434\n"
     ]
    }
   ],
   "source": [
    "readmit = df['readmitted'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Occurrences of Readmitted:\")\n",
    "print(\"Value 0:\", readmit[0])\n",
    "print(\"Value 1:\", readmit[1])\n",
    "print('%:',readmit[1]/readmit[0])\n",
    "\n",
    "X = df.drop(['readmitted'], axis=1)\n",
    "y = df['readmitted'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6ace04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88cf68ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      1.00      0.94     18084\n",
      "         1.0       0.40      0.02      0.03      2269\n",
      "\n",
      "    accuracy                           0.89     20353\n",
      "   macro avg       0.65      0.51      0.49     20353\n",
      "weighted avg       0.84      0.89      0.84     20353\n",
      "\n",
      "[[18029    55]\n",
      " [ 2232    37]]\n",
      "  Sampling Technique  Precision    Recall  F1 Score  Accuracy  \\\n",
      "0                RFC   0.835472  0.887633  0.839018  0.887633   \n",
      "\n",
      "            Confusion Matrix  \n",
      "0  [[18029, 55], [2232, 37]]  \n"
     ]
    }
   ],
   "source": [
    "rfc= RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train_pca, y_train)\n",
    "rfc_predictions = rfc.predict(X_test_pca) \n",
    "print(classification_report(y_val, rfc_predictions))\n",
    "print(confusion_matrix(y_val, rfc_predictions))\n",
    "\n",
    "report = classification_report(y_val, rfc_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, rfc_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Sampling Technique' : 'RFC',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(data)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f2a2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99b0c432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      1.00      0.94     18084\n",
      "         1.0       0.00      0.00      0.00      2269\n",
      "\n",
      "    accuracy                           0.89     20353\n",
      "   macro avg       0.44      0.50      0.47     20353\n",
      "weighted avg       0.79      0.89      0.84     20353\n",
      "\n",
      "[[18082     2]\n",
      " [ 2269     0]]\n",
      "  Sampling Technique  Precision    Recall  F1 Score  Accuracy  \\\n",
      "0                RFC   0.835472  0.887633  0.839018  0.887633   \n",
      "1                GBT   0.789454  0.888419  0.836018  0.888419   \n",
      "\n",
      "            Confusion Matrix  \n",
      "0  [[18029, 55], [2232, 37]]  \n",
      "1    [[18082, 2], [2269, 0]]  \n"
     ]
    }
   ],
   "source": [
    "gbt = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100,max_depth=3, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\n",
    "gbt.fit(X_train_pca,y_train)\n",
    "gbt_predictions = gbt.predict(X_test_pca) \n",
    "print(classification_report(y_val, gbt_predictions))\n",
    "print(confusion_matrix(y_val, gbt_predictions))\n",
    "\n",
    "report = classification_report(y_val, gbt_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, gbt_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Sampling Technique' : 'GBT',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "metrics_df = metrics_df.append(df2, ignore_index=True)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3280a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad71543b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.19804\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l1: 0.19787\n",
      "[3]\tvalid_0's l1: 0.197673\n",
      "[4]\tvalid_0's l1: 0.197465\n",
      "[5]\tvalid_0's l1: 0.19733\n",
      "[6]\tvalid_0's l1: 0.19716\n",
      "[7]\tvalid_0's l1: 0.196994\n",
      "[8]\tvalid_0's l1: 0.196885\n",
      "[9]\tvalid_0's l1: 0.19675\n",
      "[10]\tvalid_0's l1: 0.196671\n",
      "[11]\tvalid_0's l1: 0.19659\n",
      "[12]\tvalid_0's l1: 0.19648\n",
      "[13]\tvalid_0's l1: 0.196354\n",
      "[14]\tvalid_0's l1: 0.196287\n",
      "[15]\tvalid_0's l1: 0.19621\n",
      "[16]\tvalid_0's l1: 0.196104\n",
      "[17]\tvalid_0's l1: 0.195995\n",
      "[18]\tvalid_0's l1: 0.195884\n",
      "[19]\tvalid_0's l1: 0.1958\n",
      "[20]\tvalid_0's l1: 0.195803\n",
      "[21]\tvalid_0's l1: 0.195702\n",
      "[22]\tvalid_0's l1: 0.195629\n",
      "[23]\tvalid_0's l1: 0.195557\n",
      "[24]\tvalid_0's l1: 0.195533\n",
      "[25]\tvalid_0's l1: 0.19543\n",
      "[26]\tvalid_0's l1: 0.195305\n",
      "[27]\tvalid_0's l1: 0.195269\n",
      "[28]\tvalid_0's l1: 0.195231\n",
      "[29]\tvalid_0's l1: 0.195186\n",
      "[30]\tvalid_0's l1: 0.195124\n",
      "[31]\tvalid_0's l1: 0.19508\n",
      "[32]\tvalid_0's l1: 0.195047\n",
      "[33]\tvalid_0's l1: 0.195041\n",
      "[34]\tvalid_0's l1: 0.194992\n",
      "[35]\tvalid_0's l1: 0.194926\n",
      "[36]\tvalid_0's l1: 0.194934\n",
      "[37]\tvalid_0's l1: 0.194878\n",
      "[38]\tvalid_0's l1: 0.194848\n",
      "[39]\tvalid_0's l1: 0.194807\n",
      "[40]\tvalid_0's l1: 0.194764\n",
      "[41]\tvalid_0's l1: 0.194719\n",
      "[42]\tvalid_0's l1: 0.194694\n",
      "[43]\tvalid_0's l1: 0.194675\n",
      "[44]\tvalid_0's l1: 0.194649\n",
      "[45]\tvalid_0's l1: 0.19463\n",
      "[46]\tvalid_0's l1: 0.194621\n",
      "[47]\tvalid_0's l1: 0.194585\n",
      "[48]\tvalid_0's l1: 0.194565\n",
      "[49]\tvalid_0's l1: 0.194541\n",
      "[50]\tvalid_0's l1: 0.194522\n",
      "[51]\tvalid_0's l1: 0.194497\n",
      "[52]\tvalid_0's l1: 0.194472\n",
      "[53]\tvalid_0's l1: 0.194444\n",
      "[54]\tvalid_0's l1: 0.194439\n",
      "[55]\tvalid_0's l1: 0.194412\n",
      "[56]\tvalid_0's l1: 0.194362\n",
      "[57]\tvalid_0's l1: 0.194345\n",
      "[58]\tvalid_0's l1: 0.194304\n",
      "[59]\tvalid_0's l1: 0.194263\n",
      "[60]\tvalid_0's l1: 0.194244\n",
      "[61]\tvalid_0's l1: 0.194204\n",
      "[62]\tvalid_0's l1: 0.1942\n",
      "[63]\tvalid_0's l1: 0.194174\n",
      "[64]\tvalid_0's l1: 0.194148\n",
      "[65]\tvalid_0's l1: 0.194143\n",
      "[66]\tvalid_0's l1: 0.194105\n",
      "[67]\tvalid_0's l1: 0.19407\n",
      "[68]\tvalid_0's l1: 0.194031\n",
      "[69]\tvalid_0's l1: 0.194003\n",
      "[70]\tvalid_0's l1: 0.194006\n",
      "[71]\tvalid_0's l1: 0.193996\n",
      "[72]\tvalid_0's l1: 0.193998\n",
      "[73]\tvalid_0's l1: 0.193942\n",
      "[74]\tvalid_0's l1: 0.193945\n",
      "[75]\tvalid_0's l1: 0.193893\n",
      "[76]\tvalid_0's l1: 0.193899\n",
      "[77]\tvalid_0's l1: 0.193868\n",
      "[78]\tvalid_0's l1: 0.193857\n",
      "[79]\tvalid_0's l1: 0.193869\n",
      "[80]\tvalid_0's l1: 0.193842\n",
      "[81]\tvalid_0's l1: 0.193873\n",
      "[82]\tvalid_0's l1: 0.19387\n",
      "[83]\tvalid_0's l1: 0.19385\n",
      "[84]\tvalid_0's l1: 0.193815\n",
      "[85]\tvalid_0's l1: 0.193806\n",
      "[86]\tvalid_0's l1: 0.193798\n",
      "[87]\tvalid_0's l1: 0.193754\n",
      "[88]\tvalid_0's l1: 0.193724\n",
      "[89]\tvalid_0's l1: 0.193722\n",
      "[90]\tvalid_0's l1: 0.193715\n",
      "[91]\tvalid_0's l1: 0.193704\n",
      "[92]\tvalid_0's l1: 0.193693\n",
      "[93]\tvalid_0's l1: 0.193708\n",
      "[94]\tvalid_0's l1: 0.193686\n",
      "[95]\tvalid_0's l1: 0.193661\n",
      "[96]\tvalid_0's l1: 0.193643\n",
      "[97]\tvalid_0's l1: 0.19364\n",
      "[98]\tvalid_0's l1: 0.193634\n",
      "[99]\tvalid_0's l1: 0.193605\n",
      "[100]\tvalid_0's l1: 0.193619\n",
      "[101]\tvalid_0's l1: 0.193598\n",
      "[102]\tvalid_0's l1: 0.193575\n",
      "[103]\tvalid_0's l1: 0.193563\n",
      "[104]\tvalid_0's l1: 0.193562\n",
      "[105]\tvalid_0's l1: 0.193543\n",
      "[106]\tvalid_0's l1: 0.193536\n",
      "[107]\tvalid_0's l1: 0.193503\n",
      "[108]\tvalid_0's l1: 0.193501\n",
      "[109]\tvalid_0's l1: 0.193474\n",
      "[110]\tvalid_0's l1: 0.193468\n",
      "[111]\tvalid_0's l1: 0.193459\n",
      "[112]\tvalid_0's l1: 0.193476\n",
      "[113]\tvalid_0's l1: 0.193454\n",
      "[114]\tvalid_0's l1: 0.193451\n",
      "[115]\tvalid_0's l1: 0.193455\n",
      "[116]\tvalid_0's l1: 0.193445\n",
      "[117]\tvalid_0's l1: 0.193419\n",
      "[118]\tvalid_0's l1: 0.193417\n",
      "[119]\tvalid_0's l1: 0.193412\n",
      "[120]\tvalid_0's l1: 0.193389\n",
      "[121]\tvalid_0's l1: 0.193376\n",
      "[122]\tvalid_0's l1: 0.193361\n",
      "[123]\tvalid_0's l1: 0.193353\n",
      "[124]\tvalid_0's l1: 0.193366\n",
      "[125]\tvalid_0's l1: 0.193369\n",
      "[126]\tvalid_0's l1: 0.193356\n",
      "[127]\tvalid_0's l1: 0.193333\n",
      "[128]\tvalid_0's l1: 0.193363\n",
      "[129]\tvalid_0's l1: 0.193351\n",
      "[130]\tvalid_0's l1: 0.193322\n",
      "[131]\tvalid_0's l1: 0.193289\n",
      "[132]\tvalid_0's l1: 0.193288\n",
      "[133]\tvalid_0's l1: 0.19329\n",
      "[134]\tvalid_0's l1: 0.193265\n",
      "[135]\tvalid_0's l1: 0.193242\n",
      "[136]\tvalid_0's l1: 0.193231\n",
      "[137]\tvalid_0's l1: 0.193211\n",
      "[138]\tvalid_0's l1: 0.193207\n",
      "[139]\tvalid_0's l1: 0.193186\n",
      "[140]\tvalid_0's l1: 0.193175\n",
      "[141]\tvalid_0's l1: 0.193173\n",
      "[142]\tvalid_0's l1: 0.193179\n",
      "[143]\tvalid_0's l1: 0.193143\n",
      "[144]\tvalid_0's l1: 0.193113\n",
      "[145]\tvalid_0's l1: 0.193115\n",
      "[146]\tvalid_0's l1: 0.193099\n",
      "[147]\tvalid_0's l1: 0.193092\n",
      "[148]\tvalid_0's l1: 0.193073\n",
      "[149]\tvalid_0's l1: 0.193061\n",
      "[150]\tvalid_0's l1: 0.193065\n",
      "[151]\tvalid_0's l1: 0.193045\n",
      "[152]\tvalid_0's l1: 0.193035\n",
      "[153]\tvalid_0's l1: 0.193036\n",
      "[154]\tvalid_0's l1: 0.193048\n",
      "[155]\tvalid_0's l1: 0.19305\n",
      "[156]\tvalid_0's l1: 0.193072\n",
      "[157]\tvalid_0's l1: 0.193099\n",
      "[158]\tvalid_0's l1: 0.193082\n",
      "[159]\tvalid_0's l1: 0.193077\n",
      "[160]\tvalid_0's l1: 0.193067\n",
      "[161]\tvalid_0's l1: 0.193053\n",
      "[162]\tvalid_0's l1: 0.193043\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's l1: 0.193035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      1.00      0.94     18084\n",
      "         1.0       0.53      0.01      0.02      2269\n",
      "\n",
      "    accuracy                           0.89     20353\n",
      "   macro avg       0.71      0.50      0.48     20353\n",
      "weighted avg       0.85      0.89      0.84     20353\n",
      "\n",
      "[[18066    18]\n",
      " [ 2249    20]]\n",
      "  Sampling Technique  Precision    Recall  F1 Score  Accuracy  \\\n",
      "0                RFC   0.835472  0.887633  0.839018  0.887633   \n",
      "1                GBT   0.789454  0.888419  0.836018  0.888419   \n",
      "2               LGBM   0.789454  0.888419  0.836018  0.888419   \n",
      "\n",
      "            Confusion Matrix  \n",
      "0  [[18029, 55], [2232, 37]]  \n",
      "1    [[18082, 2], [2269, 0]]  \n",
      "2    [[18082, 2], [2269, 0]]  \n"
     ]
    }
   ],
   "source": [
    "neg_to_pos_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'mae',\n",
    "    'min_child_weight': 60,  # Adjust this value and experiment\n",
    "    'random_state': 42,\n",
    "    'max_delta_step': 1,\n",
    "    'verbose': -1,\n",
    "    'max_depth': 10, \n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train_pca, label=y_train)\n",
    "val_data = lgb.Dataset(X_test_pca, label=y_val)\n",
    "\n",
    "num_round = 200\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[val_data], early_stopping_rounds=10)\n",
    "\n",
    "y_pred_proba = bst.predict(X_test_pca)\n",
    "\n",
    "y_pred_class = [1 if pred > 0.5 else 0 for pred in y_pred_proba]\n",
    "\n",
    "print(classification_report(y_val, y_pred_class, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred_class))\n",
    "\n",
    "report = classification_report(y_val, gbt_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, gbt_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Sampling Technique' : 'LGBM',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "metrics_df = metrics_df.append(df2, ignore_index=True)\n",
    "print(metrics_df)\n",
    "\n",
    "metrics_df.to_csv('../data/pcaResults.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8d3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1caab94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae72cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd6edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
