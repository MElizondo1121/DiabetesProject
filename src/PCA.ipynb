{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd14ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\Mirna Elizondo\\anaconda3\\envs\\condaEnv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In C:\\Users\\Mirna Elizondo\\anaconda3\\envs\\condaEnv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In C:\\Users\\Mirna Elizondo\\anaconda3\\envs\\condaEnv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The pgf.debug rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In C:\\Users\\Mirna Elizondo\\anaconda3\\envs\\condaEnv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In C:\\Users\\Mirna Elizondo\\anaconda3\\envs\\condaEnv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102197f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64')], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/diabetes_data_encoded.csv').drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "df.columns = [re.sub(r'[^\\w\\s]', '', col) for col in df.columns]\n",
    "df.columns = [re.sub(r'[_]', ' ', col) for col in df.columns]\n",
    "df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "647ea5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of Readmitted:\n",
      "Value 0: 90406\n",
      "Value 1: 11357\n",
      "%: 0.12562219321726434\n"
     ]
    }
   ],
   "source": [
    "readmit = df['readmitted'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Occurrences of Readmitted:\")\n",
    "print(\"Value 0:\", readmit[0])\n",
    "print(\"Value 1:\", readmit[1])\n",
    "print('%:',readmit[1]/readmit[0])\n",
    "\n",
    "X = df.drop(['readmitted'], axis=1)\n",
    "y = df['readmitted'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3bede8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb0cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      1.00      0.94     18084\n",
      "         1.0       0.40      0.02      0.03      2269\n",
      "\n",
      "    accuracy                           0.89     20353\n",
      "   macro avg       0.65      0.51      0.49     20353\n",
      "weighted avg       0.84      0.89      0.84     20353\n",
      "\n",
      "[[18032    52]\n",
      " [ 2234    35]]\n",
      "  Sampling Technique  Precision    Recall  F1 Score  Accuracy  \\\n",
      "0                RFC   0.835422  0.887682  0.838866  0.887682   \n",
      "\n",
      "            Confusion Matrix  \n",
      "0  [[18032, 52], [2234, 35]]  \n"
     ]
    }
   ],
   "source": [
    "rfc= RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train_pca, y_train)\n",
    "rfc_predictions = rfc.predict(X_test_pca) \n",
    "print(classification_report(y_val, rfc_predictions))\n",
    "print(confusion_matrix(y_val, rfc_predictions))\n",
    "\n",
    "report = classification_report(y_val, rfc_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, rfc_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Sampling Technique' : 'RFC',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(data)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b7ef958",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c23f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      1.00      0.94     18084\n",
      "         1.0       0.00      0.00      0.00      2269\n",
      "\n",
      "    accuracy                           0.89     20353\n",
      "   macro avg       0.44      0.50      0.47     20353\n",
      "weighted avg       0.79      0.89      0.84     20353\n",
      "\n",
      "[[18082     2]\n",
      " [ 2269     0]]\n",
      "  Sampling Technique  Precision    Recall  F1 Score  Accuracy  \\\n",
      "0                RFC   0.835422  0.887682  0.838866  0.887682   \n",
      "1                GBT   0.789454  0.888419  0.836018  0.888419   \n",
      "\n",
      "            Confusion Matrix  \n",
      "0  [[18032, 52], [2234, 35]]  \n",
      "1    [[18082, 2], [2269, 0]]  \n"
     ]
    }
   ],
   "source": [
    "gbt = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100,max_depth=3, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\n",
    "gbt.fit(X_train_pca,y_train)\n",
    "gbt_predictions = gbt.predict(X_test_pca) \n",
    "print(classification_report(y_val, gbt_predictions))\n",
    "print(confusion_matrix(y_val, gbt_predictions))\n",
    "\n",
    "report = classification_report(y_val, gbt_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, gbt_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Sampling Technique' : 'GBT',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "metrics_df = metrics_df.append(df2, ignore_index=True)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87388cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520ca27a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'min_samples_split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-14884a8d0b0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sqrt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcat_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'min_samples_split'"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(learning_rate=0.1, n_estimators=100,max_depth=3, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\n",
    "cat.fit(X_train_pca,y_train)\n",
    "cat_predictions = gbt.predict(X_test_pca) \n",
    "print(classification_report(y_val, cat_predictions))\n",
    "print(confusion_matrix(y_val, cat_predictions))\n",
    "\n",
    "report = classification_report(y_val, cat_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, cat_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Sampling Technique' : 'CB',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "metrics_df = metrics_df.append(df2, ignore_index=True)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d958322",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b468f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_to_pos_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'mae',\n",
    "    'min_child_weight': 60,  # Adjust this value and experiment\n",
    "    'random_state': 42,\n",
    "    'max_delta_step': 1,\n",
    "    'verbose': -1,\n",
    "    'max_depth': 10, \n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train_pca, label=y_train)\n",
    "val_data = lgb.Dataset(X_test_pca, label=y_val)\n",
    "\n",
    "num_round = 200\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[val_data], early_stopping_rounds=10)\n",
    "\n",
    "y_pred_proba = bst.predict(X_test_pca)\n",
    "\n",
    "y_pred_class = [1 if pred > 0.5 else 0 for pred in y_pred_proba]\n",
    "\n",
    "print(classification_report(y_val, y_pred_class, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred_class))\n",
    "\n",
    "report = classification_report(y_val, gbt_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, gbt_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Sampling Technique' : 'LGBM',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "metrics_df = metrics_df.append(df2, ignore_index=True)\n",
    "print(metrics_df)\n",
    "\n",
    "metrics_df.to_csv('../data/pcaResults.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b6e4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac1507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557bf25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0ef72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
