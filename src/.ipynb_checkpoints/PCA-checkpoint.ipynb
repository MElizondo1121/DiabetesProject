{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d8101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f5c93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136429, 264)\n",
      "(90954, 263)\n",
      "Occurrences of Machine Failure:\n",
      "Value 0: 134281\n",
      "Value 1: 2148\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed_diabetes_data.csv').drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "failure_counts = train['Machine failure'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Occurrences of Machine Failure:\")\n",
    "print(\"Value 0:\", failure_counts[0])\n",
    "print(\"Value 1:\", failure_counts[1])\n",
    "\n",
    "X = train.drop(['Machine failure'], axis=1)\n",
    "y = train['Machine failure'].values\n",
    "X_test = test\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac45947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ed4a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26848\n",
      "           1       0.99      0.76      0.86       438\n",
      "\n",
      "    accuracy                           1.00     27286\n",
      "   macro avg       0.99      0.88      0.93     27286\n",
      "weighted avg       1.00      1.00      1.00     27286\n",
      "\n",
      "[[26843     5]\n",
      " [  104   334]]\n",
      "  Sampling Technique  Precision    Recall  F1 Score  Accuracy  \\\n",
      "0                RFC   0.995966  0.996005  0.995754  0.996005   \n",
      "\n",
      "           Confusion Matrix  \n",
      "0  [[26843, 5], [104, 334]]  \n"
     ]
    }
   ],
   "source": [
    "rfc= RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train_pca, y_train)\n",
    "rfc_predictions = rfc.predict(X_test_pca) \n",
    "print(classification_report(y_val, rfc_predictions))\n",
    "print(confusion_matrix(y_val, rfc_predictions))\n",
    "\n",
    "report = classification_report(y_val, rfc_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, rfc_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Sampling Technique' : 'RFC',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(data)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e7ef603",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['Machine failure'], axis=1)\n",
    "y = train['Machine failure'].values\n",
    "X_test = test\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84d9f4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     26848\n",
      "           1       0.67      0.77      0.72       438\n",
      "\n",
      "    accuracy                           0.99     27286\n",
      "   macro avg       0.83      0.88      0.86     27286\n",
      "weighted avg       0.99      0.99      0.99     27286\n",
      "\n",
      "[[26685   163]\n",
      " [  102   336]]\n",
      "  Sampling Technique  Precision    Recall  F1 Score  Accuracy  \\\n",
      "0                RFC   0.995966  0.996005  0.995754  0.996005   \n",
      "1                GBT   0.991010  0.990288  0.990599  0.990288   \n",
      "\n",
      "             Confusion Matrix  \n",
      "0    [[26843, 5], [104, 334]]  \n",
      "1  [[26685, 163], [102, 336]]  \n"
     ]
    }
   ],
   "source": [
    "gbt = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100,max_depth=3, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\n",
    "gbt.fit(X_train_pca,y_train)\n",
    "gbt_predictions = gbt.predict(X_test_pca) \n",
    "print(classification_report(y_val, gbt_predictions))\n",
    "print(confusion_matrix(y_val, gbt_predictions))\n",
    "\n",
    "report = classification_report(y_val, gbt_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, gbt_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Sampling Technique' : 'GBT',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "metrics_df = metrics_df.append(df, ignore_index=True)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dc4473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['Machine failure'], axis=1)\n",
    "y = train['Machine failure'].values\n",
    "X_test = test\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=125)  # Choose the number of components\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2347381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0300821\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l1: 0.0290351\n",
      "[3]\tvalid_0's l1: 0.0281168\n",
      "[4]\tvalid_0's l1: 0.0272662\n",
      "[5]\tvalid_0's l1: 0.0264926\n",
      "[6]\tvalid_0's l1: 0.0257964\n",
      "[7]\tvalid_0's l1: 0.0251694\n",
      "[8]\tvalid_0's l1: 0.0245655\n",
      "[9]\tvalid_0's l1: 0.0240188\n",
      "[10]\tvalid_0's l1: 0.0235193\n",
      "[11]\tvalid_0's l1: 0.0230526\n",
      "[12]\tvalid_0's l1: 0.0226225\n",
      "[13]\tvalid_0's l1: 0.0222268\n",
      "[14]\tvalid_0's l1: 0.0218596\n",
      "[15]\tvalid_0's l1: 0.0215185\n",
      "[16]\tvalid_0's l1: 0.0211974\n",
      "[17]\tvalid_0's l1: 0.0208967\n",
      "[18]\tvalid_0's l1: 0.0206122\n",
      "[19]\tvalid_0's l1: 0.0203417\n",
      "[20]\tvalid_0's l1: 0.020084\n",
      "[21]\tvalid_0's l1: 0.0198187\n",
      "[22]\tvalid_0's l1: 0.0195578\n",
      "[23]\tvalid_0's l1: 0.0193001\n",
      "[24]\tvalid_0's l1: 0.0190447\n",
      "[25]\tvalid_0's l1: 0.0187892\n",
      "[26]\tvalid_0's l1: 0.0185328\n",
      "[27]\tvalid_0's l1: 0.0182726\n",
      "[28]\tvalid_0's l1: 0.018008\n",
      "[29]\tvalid_0's l1: 0.0177382\n",
      "[30]\tvalid_0's l1: 0.0174679\n",
      "[31]\tvalid_0's l1: 0.0171876\n",
      "[32]\tvalid_0's l1: 0.0169029\n",
      "[33]\tvalid_0's l1: 0.0166115\n",
      "[34]\tvalid_0's l1: 0.0163162\n",
      "[35]\tvalid_0's l1: 0.0160106\n",
      "[36]\tvalid_0's l1: 0.0157022\n",
      "[37]\tvalid_0's l1: 0.0153887\n",
      "[38]\tvalid_0's l1: 0.0150728\n",
      "[39]\tvalid_0's l1: 0.014754\n",
      "[40]\tvalid_0's l1: 0.0144375\n",
      "[41]\tvalid_0's l1: 0.0141198\n",
      "[42]\tvalid_0's l1: 0.0137963\n",
      "[43]\tvalid_0's l1: 0.0134791\n",
      "[44]\tvalid_0's l1: 0.0131678\n",
      "[45]\tvalid_0's l1: 0.012858\n",
      "[46]\tvalid_0's l1: 0.0125567\n",
      "[47]\tvalid_0's l1: 0.012265\n",
      "[48]\tvalid_0's l1: 0.0119746\n",
      "[49]\tvalid_0's l1: 0.0116995\n",
      "[50]\tvalid_0's l1: 0.0114336\n",
      "[51]\tvalid_0's l1: 0.011176\n",
      "[52]\tvalid_0's l1: 0.0109329\n",
      "[53]\tvalid_0's l1: 0.0106997\n",
      "[54]\tvalid_0's l1: 0.0104784\n",
      "[55]\tvalid_0's l1: 0.0102705\n",
      "[56]\tvalid_0's l1: 0.0100747\n",
      "[57]\tvalid_0's l1: 0.00989102\n",
      "[58]\tvalid_0's l1: 0.00971737\n",
      "[59]\tvalid_0's l1: 0.00955805\n",
      "[60]\tvalid_0's l1: 0.0094071\n",
      "[61]\tvalid_0's l1: 0.00926007\n",
      "[62]\tvalid_0's l1: 0.00913207\n",
      "[63]\tvalid_0's l1: 0.00901434\n",
      "[64]\tvalid_0's l1: 0.00891231\n",
      "[65]\tvalid_0's l1: 0.0088163\n",
      "[66]\tvalid_0's l1: 0.00872861\n",
      "[67]\tvalid_0's l1: 0.00863435\n",
      "[68]\tvalid_0's l1: 0.00856126\n",
      "[69]\tvalid_0's l1: 0.0084878\n",
      "[70]\tvalid_0's l1: 0.00842811\n",
      "[71]\tvalid_0's l1: 0.00836047\n",
      "[72]\tvalid_0's l1: 0.00830276\n",
      "[73]\tvalid_0's l1: 0.00824239\n",
      "[74]\tvalid_0's l1: 0.00820087\n",
      "[75]\tvalid_0's l1: 0.00816576\n",
      "[76]\tvalid_0's l1: 0.00815024\n",
      "[77]\tvalid_0's l1: 0.00813142\n",
      "[78]\tvalid_0's l1: 0.00811031\n",
      "[79]\tvalid_0's l1: 0.00810099\n",
      "[80]\tvalid_0's l1: 0.00808433\n",
      "[81]\tvalid_0's l1: 0.00807493\n",
      "[82]\tvalid_0's l1: 0.00806267\n",
      "[83]\tvalid_0's l1: 0.00804828\n",
      "[84]\tvalid_0's l1: 0.00803983\n",
      "[85]\tvalid_0's l1: 0.0080295\n",
      "[86]\tvalid_0's l1: 0.00802414\n",
      "[87]\tvalid_0's l1: 0.00801596\n",
      "[88]\tvalid_0's l1: 0.00800719\n",
      "[89]\tvalid_0's l1: 0.00799433\n",
      "[90]\tvalid_0's l1: 0.00798873\n",
      "[91]\tvalid_0's l1: 0.00798394\n",
      "[92]\tvalid_0's l1: 0.00797644\n",
      "[93]\tvalid_0's l1: 0.00797555\n",
      "[94]\tvalid_0's l1: 0.00797055\n",
      "[95]\tvalid_0's l1: 0.00796355\n",
      "[96]\tvalid_0's l1: 0.00795752\n",
      "[97]\tvalid_0's l1: 0.00795501\n",
      "[98]\tvalid_0's l1: 0.00795346\n",
      "[99]\tvalid_0's l1: 0.00794811\n",
      "[100]\tvalid_0's l1: 0.0079447\n",
      "[101]\tvalid_0's l1: 0.0079292\n",
      "[102]\tvalid_0's l1: 0.00793035\n",
      "[103]\tvalid_0's l1: 0.00793236\n",
      "[104]\tvalid_0's l1: 0.00792914\n",
      "[105]\tvalid_0's l1: 0.00792986\n",
      "[106]\tvalid_0's l1: 0.00792974\n",
      "[107]\tvalid_0's l1: 0.00791621\n",
      "[108]\tvalid_0's l1: 0.0079211\n",
      "[109]\tvalid_0's l1: 0.00791085\n",
      "[110]\tvalid_0's l1: 0.00789905\n",
      "[111]\tvalid_0's l1: 0.00789619\n",
      "[112]\tvalid_0's l1: 0.00789589\n",
      "[113]\tvalid_0's l1: 0.00788973\n",
      "[114]\tvalid_0's l1: 0.00788028\n",
      "[115]\tvalid_0's l1: 0.00787592\n",
      "[116]\tvalid_0's l1: 0.00787425\n",
      "[117]\tvalid_0's l1: 0.00786858\n",
      "[118]\tvalid_0's l1: 0.00786479\n",
      "[119]\tvalid_0's l1: 0.00785557\n",
      "[120]\tvalid_0's l1: 0.00785524\n",
      "[121]\tvalid_0's l1: 0.00784629\n",
      "[122]\tvalid_0's l1: 0.00784455\n",
      "[123]\tvalid_0's l1: 0.007845\n",
      "[124]\tvalid_0's l1: 0.00784577\n",
      "[125]\tvalid_0's l1: 0.00784427\n",
      "[126]\tvalid_0's l1: 0.00784228\n",
      "[127]\tvalid_0's l1: 0.00784006\n",
      "[128]\tvalid_0's l1: 0.00782977\n",
      "[129]\tvalid_0's l1: 0.00782363\n",
      "[130]\tvalid_0's l1: 0.00782304\n",
      "[131]\tvalid_0's l1: 0.00782207\n",
      "[132]\tvalid_0's l1: 0.00781753\n",
      "[133]\tvalid_0's l1: 0.0078161\n",
      "[134]\tvalid_0's l1: 0.00781394\n",
      "[135]\tvalid_0's l1: 0.00781185\n",
      "[136]\tvalid_0's l1: 0.00780948\n",
      "[137]\tvalid_0's l1: 0.00780087\n",
      "[138]\tvalid_0's l1: 0.00780017\n",
      "[139]\tvalid_0's l1: 0.00780129\n",
      "[140]\tvalid_0's l1: 0.00780059\n",
      "[141]\tvalid_0's l1: 0.00779577\n",
      "[142]\tvalid_0's l1: 0.00779693\n",
      "[143]\tvalid_0's l1: 0.00779605\n",
      "[144]\tvalid_0's l1: 0.00779398\n",
      "[145]\tvalid_0's l1: 0.00778976\n",
      "[146]\tvalid_0's l1: 0.00779045\n",
      "[147]\tvalid_0's l1: 0.0077855\n",
      "[148]\tvalid_0's l1: 0.00778642\n",
      "[149]\tvalid_0's l1: 0.00778722\n",
      "[150]\tvalid_0's l1: 0.00778058\n",
      "[151]\tvalid_0's l1: 0.00777471\n",
      "[152]\tvalid_0's l1: 0.00777037\n",
      "[153]\tvalid_0's l1: 0.00776725\n",
      "[154]\tvalid_0's l1: 0.00776679\n",
      "[155]\tvalid_0's l1: 0.00776526\n",
      "[156]\tvalid_0's l1: 0.00776757\n",
      "[157]\tvalid_0's l1: 0.0077625\n",
      "[158]\tvalid_0's l1: 0.00776297\n",
      "[159]\tvalid_0's l1: 0.00775835\n",
      "[160]\tvalid_0's l1: 0.00775836\n",
      "[161]\tvalid_0's l1: 0.00775783\n",
      "[162]\tvalid_0's l1: 0.00775481\n",
      "[163]\tvalid_0's l1: 0.0077541\n",
      "[164]\tvalid_0's l1: 0.00775272\n",
      "[165]\tvalid_0's l1: 0.00774818\n",
      "[166]\tvalid_0's l1: 0.00774676\n",
      "[167]\tvalid_0's l1: 0.00774613\n",
      "[168]\tvalid_0's l1: 0.00774698\n",
      "[169]\tvalid_0's l1: 0.00774724\n",
      "[170]\tvalid_0's l1: 0.00774092\n",
      "[171]\tvalid_0's l1: 0.00774125\n",
      "[172]\tvalid_0's l1: 0.00774113\n",
      "[173]\tvalid_0's l1: 0.00774182\n",
      "[174]\tvalid_0's l1: 0.0077377\n",
      "[175]\tvalid_0's l1: 0.00773362\n",
      "[176]\tvalid_0's l1: 0.00772788\n",
      "[177]\tvalid_0's l1: 0.00772813\n",
      "[178]\tvalid_0's l1: 0.00772887\n",
      "[179]\tvalid_0's l1: 0.00772692\n",
      "[180]\tvalid_0's l1: 0.00772768\n",
      "[181]\tvalid_0's l1: 0.00772743\n",
      "[182]\tvalid_0's l1: 0.00772822\n",
      "[183]\tvalid_0's l1: 0.00772835\n",
      "[184]\tvalid_0's l1: 0.00772363\n",
      "[185]\tvalid_0's l1: 0.00771966\n",
      "[186]\tvalid_0's l1: 0.00771626\n",
      "[187]\tvalid_0's l1: 0.00771083\n",
      "[188]\tvalid_0's l1: 0.00771016\n",
      "[189]\tvalid_0's l1: 0.00771145\n",
      "[190]\tvalid_0's l1: 0.00771485\n",
      "[191]\tvalid_0's l1: 0.00771038\n",
      "[192]\tvalid_0's l1: 0.0077105\n",
      "[193]\tvalid_0's l1: 0.00770941\n",
      "[194]\tvalid_0's l1: 0.00770977\n",
      "[195]\tvalid_0's l1: 0.00770536\n",
      "[196]\tvalid_0's l1: 0.00770739\n",
      "[197]\tvalid_0's l1: 0.00770769\n",
      "[198]\tvalid_0's l1: 0.00770733\n",
      "[199]\tvalid_0's l1: 0.00770894\n",
      "[200]\tvalid_0's l1: 0.00770314\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l1: 0.00770314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     26848\n",
      "           1       0.99      0.77      0.86       438\n",
      "\n",
      "    accuracy                           1.00     27286\n",
      "   macro avg       0.99      0.88      0.93     27286\n",
      "weighted avg       1.00      1.00      1.00     27286\n",
      "\n",
      "[[26845     3]\n",
      " [  102   336]]\n",
      "  Sampling Technique  Precision    Recall  F1 Score  Accuracy  \\\n",
      "0                RFC   0.995966  0.996005  0.995754  0.996005   \n",
      "1                GBT   0.991010  0.990288  0.990599  0.990288   \n",
      "2               LGBM   0.991010  0.990288  0.990599  0.990288   \n",
      "\n",
      "             Confusion Matrix  \n",
      "0    [[26843, 5], [104, 334]]  \n",
      "1  [[26685, 163], [102, 336]]  \n",
      "2  [[26685, 163], [102, 336]]  \n"
     ]
    }
   ],
   "source": [
    "neg_to_pos_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'mae',\n",
    "    'min_child_weight': 60,  # Adjust this value and experiment\n",
    "    'random_state': 42,\n",
    "    'max_delta_step': 1,\n",
    "    'verbose': -1,\n",
    "    'max_depth': 10, \n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train_pca, label=y_train)\n",
    "val_data = lgb.Dataset(X_test_pca, label=y_val)\n",
    "\n",
    "num_round = 200\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[val_data], early_stopping_rounds=10)\n",
    "\n",
    "y_pred_proba = bst.predict(X_test_pca)\n",
    "\n",
    "y_pred_class = [1 if pred > 0.5 else 0 for pred in y_pred_proba]\n",
    "\n",
    "print(classification_report(y_val, y_pred_class, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred_class))\n",
    "\n",
    "report = classification_report(y_val, gbt_predictions, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_val, gbt_predictions)\n",
    "\n",
    "# Extract metrics from classification report\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Sampling Technique' : 'LGBM',\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Confusion Matrix': [conf_matrix]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "metrics_df = metrics_df.append(df, ignore_index=True)\n",
    "print(metrics_df)\n",
    "\n",
    "metrics_df.to_csv('../data/pcaResults.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6b6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4f8ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff64620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde4e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
